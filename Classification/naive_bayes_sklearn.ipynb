{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from foundation import load_category_mapper, sample, load_stop_words\n",
    "import jieba\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category Mapper & Stop Words\n",
    "\n",
    "Required Files\n",
    "\n",
    "- category_mapper.json\n",
    "- stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load category mapper from the json file. The key is the category string, and the value is corresponding int value.\n",
    "cat_mapper = load_category_mapper()\n",
    "# load stop words from json\n",
    "stop_words = load_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: ent, val: 10\n",
      "stop words len: 1266\n"
     ]
    }
   ],
   "source": [
    "print(f\"key: ent, val: {cat_mapper['ent']}\")\n",
    "print(f\"stop words len: {len(stop_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Corpus generation:\n",
    "\n",
    "- `__format_str(string)` removes any characters in the string that not belongs to chinese.\n",
    "- Spliting the word by jieba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __is_chinese(uchar):\n",
    "    if u'\\u4e00' <= uchar <= u'\\u9fa5':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def __format_str(string):\n",
    "    content_str = ''\n",
    "    for i in string:\n",
    "        if __is_chinese(i):\n",
    "            content_str = content_str + i\n",
    "        else:\n",
    "            content_str += \",\"\n",
    "    return content_str\n",
    "\n",
    "def generate_corpus(dataset, stopwords):\n",
    "    corpus = list()\n",
    "    for idx, row in dataset.iterrows():\n",
    "        if idx == 1:\n",
    "            print(f\"The progress of generating corpus is {idx * 100 / len(dataset)}% ({idx}/{len(dataset)}).\")\n",
    "        elif idx % 100 == 0:\n",
    "            print(f\"The progress of generating corpus is {idx * 100 / len(dataset)}% ({idx}/{len(dataset)}).\")\n",
    "        text = __format_str(row[\"title\"] + row[\"content\"])\n",
    "        words = jieba.cut(text)\n",
    "        pwords = list()\n",
    "        for word in words:\n",
    "            if word not in stopwords:\n",
    "                pwords.append(word)\n",
    "        text = \" \".join(pwords)\n",
    "        corpus.append(text)\n",
    "    print(f\"The progress of generating corpus is 100% ({len(corpus)}/{len(corpus)}).\")\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enrich your stopwords by `corpus_count()`, which will list the top 100, specified by `size`, most frequent words. If the word has no meaning, you could append it into `stopwords.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_count(corpus, size=100):\n",
    "    corpus_split = [item for sublist in [i.split(\" \") for i in corpus] for item in sublist]\n",
    "    count_words = dict(Counter(corpus_split))\n",
    "    outputwords_sorted = sorted(count_words.items(), key=lambda x: x[1], reverse=True)[:size]\n",
    "    print(outputwords_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vector representing `y` from database, which must have a column named category.\n",
    "def generate_y(dataset):\n",
    "    y = np.zeros((len(dataset),))\n",
    "    for i in range(len(dataset)):\n",
    "        y[i] = cat_mapper[dataset.iloc[i, :][\"category\"]]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Multinomial Naive Bayes with Sampled Data and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10,000 data from the dataset.\n",
    "sample(\"news.csv\", 10000, \"news-sample.csv\", \"news-sample-train.csv\", \"news-sample-test.csv\", 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sampled train dataset and sampled test dataset\n",
    "sampled_train_dataset = pd.read_csv(\"news-sample-train.csv\")\n",
    "sampled_test_dataset = pd.read_csv(\"news-sample-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled_train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fd524a513ca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_train_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_test_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampled_train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(sampled_train_dataset.head())\n",
    "print(\"-------------------------\")\n",
    "print(sampled_test_dataset.head())\n",
    "print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/5l/6k3fjmx956sb52cw3f7w5x700000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The progress of generating corpus is 0.0% (0/7000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.837 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The progress of generating corpus is 0.014285714285714285% (1/7000).\n",
      "The progress of generating corpus is 1.4285714285714286% (100/7000).\n",
      "The progress of generating corpus is 2.857142857142857% (200/7000).\n",
      "The progress of generating corpus is 4.285714285714286% (300/7000).\n",
      "The progress of generating corpus is 5.714285714285714% (400/7000).\n",
      "The progress of generating corpus is 7.142857142857143% (500/7000).\n",
      "The progress of generating corpus is 8.571428571428571% (600/7000).\n",
      "The progress of generating corpus is 10.0% (700/7000).\n",
      "The progress of generating corpus is 11.428571428571429% (800/7000).\n",
      "The progress of generating corpus is 12.857142857142858% (900/7000).\n",
      "The progress of generating corpus is 14.285714285714286% (1000/7000).\n",
      "The progress of generating corpus is 15.714285714285714% (1100/7000).\n",
      "The progress of generating corpus is 17.142857142857142% (1200/7000).\n",
      "The progress of generating corpus is 18.571428571428573% (1300/7000).\n",
      "The progress of generating corpus is 20.0% (1400/7000).\n",
      "The progress of generating corpus is 21.428571428571427% (1500/7000).\n",
      "The progress of generating corpus is 22.857142857142858% (1600/7000).\n",
      "The progress of generating corpus is 24.285714285714285% (1700/7000).\n",
      "The progress of generating corpus is 25.714285714285715% (1800/7000).\n",
      "The progress of generating corpus is 27.142857142857142% (1900/7000).\n",
      "The progress of generating corpus is 28.571428571428573% (2000/7000).\n",
      "The progress of generating corpus is 30.0% (2100/7000).\n",
      "The progress of generating corpus is 31.428571428571427% (2200/7000).\n",
      "The progress of generating corpus is 32.857142857142854% (2300/7000).\n",
      "The progress of generating corpus is 34.285714285714285% (2400/7000).\n",
      "The progress of generating corpus is 35.714285714285715% (2500/7000).\n",
      "The progress of generating corpus is 37.142857142857146% (2600/7000).\n",
      "The progress of generating corpus is 38.57142857142857% (2700/7000).\n",
      "The progress of generating corpus is 40.0% (2800/7000).\n",
      "The progress of generating corpus is 41.42857142857143% (2900/7000).\n",
      "The progress of generating corpus is 42.857142857142854% (3000/7000).\n",
      "The progress of generating corpus is 44.285714285714285% (3100/7000).\n",
      "The progress of generating corpus is 45.714285714285715% (3200/7000).\n",
      "The progress of generating corpus is 47.142857142857146% (3300/7000).\n",
      "The progress of generating corpus is 48.57142857142857% (3400/7000).\n",
      "The progress of generating corpus is 50.0% (3500/7000).\n",
      "The progress of generating corpus is 51.42857142857143% (3600/7000).\n",
      "The progress of generating corpus is 52.857142857142854% (3700/7000).\n",
      "The progress of generating corpus is 54.285714285714285% (3800/7000).\n",
      "The progress of generating corpus is 55.714285714285715% (3900/7000).\n",
      "The progress of generating corpus is 57.142857142857146% (4000/7000).\n",
      "The progress of generating corpus is 58.57142857142857% (4100/7000).\n",
      "The progress of generating corpus is 60.0% (4200/7000).\n",
      "The progress of generating corpus is 61.42857142857143% (4300/7000).\n",
      "The progress of generating corpus is 62.857142857142854% (4400/7000).\n",
      "The progress of generating corpus is 64.28571428571429% (4500/7000).\n",
      "The progress of generating corpus is 65.71428571428571% (4600/7000).\n",
      "The progress of generating corpus is 67.14285714285714% (4700/7000).\n",
      "The progress of generating corpus is 68.57142857142857% (4800/7000).\n",
      "The progress of generating corpus is 70.0% (4900/7000).\n",
      "The progress of generating corpus is 71.42857142857143% (5000/7000).\n",
      "The progress of generating corpus is 72.85714285714286% (5100/7000).\n",
      "The progress of generating corpus is 74.28571428571429% (5200/7000).\n",
      "The progress of generating corpus is 75.71428571428571% (5300/7000).\n",
      "The progress of generating corpus is 77.14285714285714% (5400/7000).\n",
      "The progress of generating corpus is 78.57142857142857% (5500/7000).\n",
      "The progress of generating corpus is 80.0% (5600/7000).\n",
      "The progress of generating corpus is 81.42857142857143% (5700/7000).\n",
      "The progress of generating corpus is 82.85714285714286% (5800/7000).\n",
      "The progress of generating corpus is 84.28571428571429% (5900/7000).\n",
      "The progress of generating corpus is 85.71428571428571% (6000/7000).\n",
      "The progress of generating corpus is 87.14285714285714% (6100/7000).\n",
      "The progress of generating corpus is 88.57142857142857% (6200/7000).\n",
      "The progress of generating corpus is 90.0% (6300/7000).\n",
      "The progress of generating corpus is 91.42857142857143% (6400/7000).\n",
      "The progress of generating corpus is 92.85714285714286% (6500/7000).\n",
      "The progress of generating corpus is 94.28571428571429% (6600/7000).\n",
      "The progress of generating corpus is 95.71428571428571% (6700/7000).\n",
      "The progress of generating corpus is 97.14285714285714% (6800/7000).\n",
      "The progress of generating corpus is 98.57142857142857% (6900/7000).\n",
      "The progress of generating corpus is 100% (7000/7000).\n",
      "The progress of generating corpus is 0.0% (0/3000).\n",
      "The progress of generating corpus is 0.03333333333333333% (1/3000).\n",
      "The progress of generating corpus is 3.3333333333333335% (100/3000).\n",
      "The progress of generating corpus is 6.666666666666667% (200/3000).\n",
      "The progress of generating corpus is 10.0% (300/3000).\n",
      "The progress of generating corpus is 13.333333333333334% (400/3000).\n",
      "The progress of generating corpus is 16.666666666666668% (500/3000).\n",
      "The progress of generating corpus is 20.0% (600/3000).\n",
      "The progress of generating corpus is 23.333333333333332% (700/3000).\n",
      "The progress of generating corpus is 26.666666666666668% (800/3000).\n",
      "The progress of generating corpus is 30.0% (900/3000).\n",
      "The progress of generating corpus is 33.333333333333336% (1000/3000).\n",
      "The progress of generating corpus is 36.666666666666664% (1100/3000).\n",
      "The progress of generating corpus is 40.0% (1200/3000).\n",
      "The progress of generating corpus is 43.333333333333336% (1300/3000).\n",
      "The progress of generating corpus is 46.666666666666664% (1400/3000).\n",
      "The progress of generating corpus is 50.0% (1500/3000).\n",
      "The progress of generating corpus is 53.333333333333336% (1600/3000).\n",
      "The progress of generating corpus is 56.666666666666664% (1700/3000).\n",
      "The progress of generating corpus is 60.0% (1800/3000).\n",
      "The progress of generating corpus is 63.333333333333336% (1900/3000).\n",
      "The progress of generating corpus is 66.66666666666667% (2000/3000).\n",
      "The progress of generating corpus is 70.0% (2100/3000).\n",
      "The progress of generating corpus is 73.33333333333333% (2200/3000).\n",
      "The progress of generating corpus is 76.66666666666667% (2300/3000).\n",
      "The progress of generating corpus is 80.0% (2400/3000).\n",
      "The progress of generating corpus is 83.33333333333333% (2500/3000).\n",
      "The progress of generating corpus is 86.66666666666667% (2600/3000).\n",
      "The progress of generating corpus is 90.0% (2700/3000).\n",
      "The progress of generating corpus is 93.33333333333333% (2800/3000).\n",
      "The progress of generating corpus is 96.66666666666667% (2900/3000).\n",
      "The progress of generating corpus is 100% (3000/3000).\n"
     ]
    }
   ],
   "source": [
    "sampled_train_corpus = generate_corpus(sampled_train_dataset, stop_words)\n",
    "sampled_test_corpus = generate_corpus(sampled_test_dataset, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "送 拉杆箱 富士通 新低 售 富士通 外观设计 采用 简约 风格 以轻 无边 镁合金 顶盖 线条 唯美 内饰 依然 十分 干净 尽显 华丽 风格 搭配 寸 流明 超炫丽 宽屏 效果 清晰 自然 整机 功能 全面 摄像头 功能 一应俱全 不足 重量 便携性 十分 突出 适合 外出 携带 点评 富士通 轻薄 系列 款 富士通 整机 配置 均衡 稳定 采用 处理器 满足用户 需求 整机 突出 轻薄 化 特点 外观 做工 精致 适合 外出 携带 整机 功能 全面 续航力 算 不错 价位 依然 偏高 喜欢 用户 联系 以下 商家 产品型号 富士通 星 钻 黑 产品价格 送 拉杆箱 商家 名称 北京 惠泽 八方 科技 商家 地址 中关村 科贸 电子城 数字 物流 港 层 室 商家 电话 商家 联系人 宫 松岗 富士通 屏幕 大小 寸 重量 公斤 类型 高端 轻薄 已有 位 用户 评论 点击 查看 评论 推荐 买 观望\n"
     ]
    }
   ],
   "source": [
    "print(sampled_train_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('公司', 8324), ('中国', 7530), ('市场', 6854), ('美国', 3741), ('时间', 3731), ('企业', 3663), ('比赛', 3573), ('发展', 3499), ('投资', 2967), ('亿元', 2920), ('经济', 2891), ('基金', 2838), ('出现', 2806), ('情况', 2748), ('工作', 2628), ('技术', 2619), ('产品', 2548), ('北京', 2509), ('增长', 2460), ('影响', 2440), ('数据', 2426), ('用户', 2347), ('信息', 2345), ('手机', 2246), ('行业', 2238), ('相关', 2237), ('国家', 2154), ('科技', 2153), ('提供', 2114), ('希望', 2077), ('国际', 2056), ('业务', 2042), ('资金', 2014), ('未来', 1949), ('学生', 1942), ('银行', 1926), ('全球', 1922), ('股', 1919), ('表现', 1913), ('价格', 1902), ('服务', 1901), ('平台', 1862), ('进入', 1856), ('计划', 1847), ('选择', 1836), ('重要', 1814), ('项目', 1807), ('使用', 1783), ('只', 1770), ('发布', 1769), ('发现', 1763), ('超过', 1757), ('网络', 1755), ('专业', 1751), ('支持', 1745), ('球队', 1736), ('球员', 1732), ('孩子', 1696), ('一定', 1696), ('关注', 1683), ('政策', 1677), ('能力', 1658), ('学校', 1623), ('万元', 1623), ('达到', 1617), ('微博', 1615), ('去年', 1593), ('美元', 1588), ('报道', 1587), ('管理', 1585), ('实现', 1583), ('媒体', 1582), ('机会', 1570), ('岁', 1565), ('方式', 1556), ('考生', 1545), ('应该', 1533), ('合作', 1529), ('世界', 1526), ('研究', 1515), ('看到', 1497), ('娱乐', 1488), ('集团', 1482), ('国内', 1474), ('人民币', 1459), ('上市', 1454), ('投资者', 1451), ('完成', 1442), ('活动', 1438), ('上涨', 1434), ('比较', 1432), ('接受', 1408), ('机构', 1406), ('消息', 1405), ('最大', 1377), ('了解', 1367), ('教育', 1364), ('内容', 1362), ('风险', 1361), ('发生', 1360)]\n",
      "\n",
      "[('公司', 3896), ('中国', 3337), ('市场', 2859), ('美国', 1763), ('时间', 1698), ('基金', 1642), ('投资', 1525), ('经济', 1431), ('比赛', 1415), ('发展', 1411), ('企业', 1341), ('亿元', 1252), ('工作', 1200), ('出现', 1164), ('情况', 1141), ('手机', 1099), ('银行', 1098), ('产品', 1057), ('影响', 1045), ('相关', 1019), ('技术', 987), ('数据', 981), ('北京', 976), ('增长', 974), ('行业', 968), ('用户', 912), ('项目', 907), ('信息', 881), ('专业', 881), ('提供', 872), ('发现', 871), ('孩子', 868), ('业务', 867), ('资金', 862), ('学生', 857), ('考生', 855), ('希望', 837), ('球员', 830), ('国家', 830), ('进入', 822), ('支持', 821), ('使用', 811), ('国内', 799), ('重要', 798), ('选择', 795), ('学校', 789), ('超过', 777), ('计划', 777), ('达到', 769), ('股', 763), ('只', 761), ('未来', 752), ('国际', 748), ('表现', 747), ('一定', 747), ('服务', 742), ('价格', 736), ('全球', 735), ('关注', 733), ('政策', 722), ('看到', 718), ('万元', 709), ('科技', 705), ('网络', 703), ('球队', 698), ('集团', 689), ('方式', 682), ('平台', 680), ('报道', 675), ('能力', 671), ('正在', 664), ('了解', 664), ('两个', 664), ('岁', 658), ('比较', 656), ('美元', 654), ('汽车', 650), ('管理', 649), ('发布', 649), ('去年', 640), ('上市', 636), ('媒体', 635), ('机构', 633), ('上海', 631), ('部分', 627), ('增加', 627), ('应该', 624), ('来说', 621), ('合作', 621), ('机会', 618), ('当时', 616), ('分钟', 614), ('电影', 610), ('亿美元', 602), ('实现', 599), ('之前', 596), ('世界', 596), ('风险', 594), ('互联网', 594), ('得到', 591)]\n"
     ]
    }
   ],
   "source": [
    "corpus_count(sampled_train_corpus)\n",
    "print()\n",
    "corpus_count(sampled_test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer & transformer\n",
    "counter_vectorizer = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "# train_X & test_X\n",
    "cvectors_train_X = counter_vectorizer.fit_transform(sampled_train_corpus)\n",
    "train_X = tfidf_transformer.fit_transform(cvectors_train_X)\n",
    "test_X = counter_vectorizer.transform(sampled_test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 528)\t1\n",
      "  (0, 3697)\t1\n",
      "  (0, 3750)\t1\n",
      "  (0, 5143)\t1\n",
      "  (0, 8978)\t1\n",
      "  (0, 8985)\t1\n",
      "  (0, 10767)\t1\n",
      "  (0, 11037)\t1\n",
      "  (0, 11112)\t1\n",
      "  (0, 13432)\t2\n",
      "  (0, 13599)\t1\n",
      "  (0, 14615)\t1\n",
      "  (0, 14663)\t1\n",
      "  (0, 16257)\t2\n",
      "  (0, 16353)\t1\n",
      "  (0, 16576)\t1\n",
      "  (0, 17761)\t1\n",
      "  (0, 22067)\t3\n",
      "  (0, 22954)\t1\n",
      "  (0, 23495)\t2\n",
      "  (0, 23998)\t1\n",
      "  (0, 29235)\t1\n",
      "  (0, 31359)\t1\n",
      "  (0, 31512)\t5\n",
      "  (0, 31721)\t1\n",
      "  :\t:\n",
      "  (6999, 103639)\t2\n",
      "  (6999, 104081)\t4\n",
      "  (6999, 104163)\t1\n",
      "  (6999, 104920)\t1\n",
      "  (6999, 105333)\t1\n",
      "  (6999, 105855)\t1\n",
      "  (6999, 106413)\t1\n",
      "  (6999, 106873)\t1\n",
      "  (6999, 107429)\t1\n",
      "  (6999, 107996)\t1\n",
      "  (6999, 108419)\t1\n",
      "  (6999, 108603)\t2\n",
      "  (6999, 110106)\t1\n",
      "  (6999, 110568)\t2\n",
      "  (6999, 110598)\t1\n",
      "  (6999, 110634)\t2\n",
      "  (6999, 111047)\t1\n",
      "  (6999, 111298)\t1\n",
      "  (6999, 111677)\t2\n",
      "  (6999, 114137)\t1\n",
      "  (6999, 116594)\t1\n",
      "  (6999, 116802)\t1\n",
      "  (6999, 116803)\t1\n",
      "  (6999, 117574)\t1\n",
      "  (6999, 120207)\t1\n"
     ]
    }
   ],
   "source": [
    "print(cvectors_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = generate_y(sampled_train_dataset)\n",
    "test_y = generate_y(sampled_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000,)\n",
      "(3000,)\n",
      "[28. 22. 28. ... 28. 27. 12.]\n",
      "[28. 12. 27. ... 26. 27. 26.]\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)\n",
    "print(test_y.shape)\n",
    "print(train_y)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict & Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.746\n"
     ]
    }
   ],
   "source": [
    "pred_y = model.predict(test_X)\n",
    "print(f\"accuracy score: {accuracy_score(test_y, pred_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
