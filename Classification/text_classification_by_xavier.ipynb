{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from foundation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Multinomial Naive Bayes with Sampled Data and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(dspath, n, sampledspath, traindspath, testdspath, traincorpuspath, testcorpuspath, testsize):\n",
    "    print(f\">>> Loading dataset from \\\"{dspath}\\\".\")\n",
    "    data = pd.read_csv(dspath).sample(n)\n",
    "    print(\">>> Saving samples.\")\n",
    "    data.to_csv(sampledspath)\n",
    "    print(\">>> Spliting dataset.\")\n",
    "    train, test = train_test_split(data, test_size=testsize)\n",
    "    print(f\"train.shape: {train.shape}\")\n",
    "    print(f\"test.shape: {test.shape}\")\n",
    "    print(\">>> Saving the train and the test dataset.\")\n",
    "    print(\">>> Task 1/2: Train dataset\")\n",
    "    train.to_csv(traindspath, index=False)\n",
    "    print(\">>> Task 2/2: Test dataset\")\n",
    "    test.to_csv(testdspath, index=False)\n",
    "    print(\">>> Generating corpus.\")\n",
    "    print(\">>> Task 1/2: Train corpus\")\n",
    "    train_corpus = generate_corpus(train, stop_words)\n",
    "    print(\">>> Task 2/2: Test corpus\")\n",
    "    test_corpus = generate_corpus(test, stop_words)\n",
    "    print(f\"train_corpus len: {len(train_corpus)}\")\n",
    "    print(f\"test_corpus len: {len(test_corpus)}\")\n",
    "    print(\">>> Saving the train and the test corpus.\")\n",
    "    print(\">>> Task 1/2: Train corpus\")\n",
    "    pd.DataFrame(train_corpus).to_csv(traincorpuspath, index=False)\n",
    "    print(\">>> Task 2/2: Test corpus\")\n",
    "    pd.DataFrame(test_corpus).to_csv(testcorpuspath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading dataset from \"news.csv\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xavier/Development/GraduateCourses/DataMinig/TextClassification/Classification/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3338: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saving samples.\n",
      ">>> Spliting dataset.\n",
      "train.shape: (25000, 7)\n",
      "test.shape: (25000, 7)\n",
      ">>> Saving the train and the test dataset.\n",
      ">>> Task 1/2: Train dataset\n",
      ">>> Task 2/2: Test dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/5l/6k3fjmx956sb52cw3f7w5x700000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Generating corpus.\n",
      ">>> Task 1/2: Train corpus\n",
      "The progress of generating corpus is 0.0% (0/25000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.643 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The progress of generating corpus is 4.0% (1000/25000).\n",
      "The progress of generating corpus is 8.0% (2000/25000).\n",
      "The progress of generating corpus is 12.0% (3000/25000).\n",
      "The progress of generating corpus is 16.0% (4000/25000).\n",
      "The progress of generating corpus is 20.0% (5000/25000).\n",
      "The progress of generating corpus is 24.0% (6000/25000).\n",
      "The progress of generating corpus is 28.0% (7000/25000).\n",
      "The progress of generating corpus is 32.0% (8000/25000).\n",
      "The progress of generating corpus is 36.0% (9000/25000).\n",
      "The progress of generating corpus is 40.0% (10000/25000).\n",
      "The progress of generating corpus is 44.0% (11000/25000).\n",
      "The progress of generating corpus is 48.0% (12000/25000).\n",
      "The progress of generating corpus is 52.0% (13000/25000).\n",
      "The progress of generating corpus is 56.0% (14000/25000).\n",
      "The progress of generating corpus is 60.0% (15000/25000).\n",
      "The progress of generating corpus is 64.0% (16000/25000).\n",
      "The progress of generating corpus is 68.0% (17000/25000).\n",
      "The progress of generating corpus is 72.0% (18000/25000).\n",
      "The progress of generating corpus is 76.0% (19000/25000).\n",
      "The progress of generating corpus is 80.0% (20000/25000).\n",
      "The progress of generating corpus is 84.0% (21000/25000).\n",
      "The progress of generating corpus is 88.0% (22000/25000).\n",
      "The progress of generating corpus is 92.0% (23000/25000).\n",
      "The progress of generating corpus is 96.0% (24000/25000).\n",
      "The progress of generating corpus is 100% (25000/25000).\n",
      ">>> Task 2/2: Test corpus\n",
      "The progress of generating corpus is 0.0% (0/25000).\n",
      "The progress of generating corpus is 4.0% (1000/25000).\n",
      "The progress of generating corpus is 8.0% (2000/25000).\n",
      "The progress of generating corpus is 12.0% (3000/25000).\n",
      "The progress of generating corpus is 16.0% (4000/25000).\n",
      "The progress of generating corpus is 20.0% (5000/25000).\n",
      "The progress of generating corpus is 24.0% (6000/25000).\n",
      "The progress of generating corpus is 28.0% (7000/25000).\n",
      "The progress of generating corpus is 32.0% (8000/25000).\n",
      "The progress of generating corpus is 36.0% (9000/25000).\n",
      "The progress of generating corpus is 40.0% (10000/25000).\n",
      "The progress of generating corpus is 44.0% (11000/25000).\n",
      "The progress of generating corpus is 48.0% (12000/25000).\n",
      "The progress of generating corpus is 52.0% (13000/25000).\n",
      "The progress of generating corpus is 56.0% (14000/25000).\n",
      "The progress of generating corpus is 60.0% (15000/25000).\n",
      "The progress of generating corpus is 64.0% (16000/25000).\n",
      "The progress of generating corpus is 68.0% (17000/25000).\n",
      "The progress of generating corpus is 72.0% (18000/25000).\n",
      "The progress of generating corpus is 76.0% (19000/25000).\n",
      "The progress of generating corpus is 80.0% (20000/25000).\n",
      "The progress of generating corpus is 84.0% (21000/25000).\n",
      "The progress of generating corpus is 88.0% (22000/25000).\n",
      "The progress of generating corpus is 92.0% (23000/25000).\n",
      "The progress of generating corpus is 96.0% (24000/25000).\n",
      "The progress of generating corpus is 100% (25000/25000).\n",
      "train_corpus len: 25000\n",
      "test_corpus len: 25000\n",
      ">>> Saving the train and the test corpus.\n",
      ">>> Task 1/2: Train corpus\n",
      ">>> Task 2/2: Test corpus\n"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "sample(\"news.csv\", 50000, \"news-sample.csv\", \"news-sample-train.csv\", \"news-sample-test.csv\", \"news-corpus-sample-train.csv\", \"news-corpus-sample-test.csv\", 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_corpus = pd.read_csv(\"news-corpus-sample-train.csv\").stack().tolist()\n",
    "sampled_test_corpus = pd.read_csv(\"news-corpus-sample-test.csv\").stack().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled_train_corpus shape: 25000\n",
      "sampled_test_corpus shape: 25000\n",
      "男子 偷 银行 窃走 万元 假币 心存侥幸 消费 被捕 凌晨 时许 占 攀爬 脚手架 进入 正在 装修 银行 二楼 会议室 办公桌 抽屉 盗走 假 人民币 万元 占 发现自己 盗得 假币 抱 侥幸心理 县城 餐馆 假币 付账 店主 报警 抓获\n"
     ]
    }
   ],
   "source": [
    "print(f\"sampled_train_corpus shape: {len(sampled_train_corpus)}\")\n",
    "print(f\"sampled_test_corpus shape: {len(sampled_test_corpus)}\")\n",
    "print(sampled_train_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> sampled_train_corpus\n",
      "[('公司', 5450), ('中国', 5190), ('市场', 5026), ('美国', 2614), ('时间', 2566), ('发展', 2551), ('比赛', 2358), ('基金', 2266), ('企业', 2223), ('经济', 2149), ('投资', 2142), ('亿元', 2112), ('技术', 2052), ('工作', 1947), ('产品', 1925), ('银行', 1849), ('情况', 1838), ('数据', 1804), ('出现', 1792), ('增长', 1783), ('影响', 1720), ('信息', 1713), ('手机', 1613), ('行业', 1593), ('平台', 1557), ('用户', 1552), ('提供', 1515), ('希望', 1461), ('相关', 1459), ('北京', 1444), ('科技', 1436), ('业务', 1434), ('服务', 1416), ('未来', 1415), ('球员', 1408), ('价格', 1372), ('国家', 1341), ('表现', 1313), ('重要', 1306), ('发现', 1292), ('计划', 1290), ('选择', 1283), ('实现', 1276), ('管理', 1265), ('股', 1262), ('超过', 1261), ('进入', 1257), ('支持', 1252), ('专业', 1241), ('国际', 1232), ('球队', 1226), ('全球', 1222), ('资金', 1189), ('使用', 1179), ('岁', 1176), ('只', 1164), ('孩子', 1152), ('美元', 1140), ('发布', 1138), ('学校', 1131), ('政策', 1127), ('机会', 1124), ('达到', 1123), ('一定', 1116), ('方式', 1114), ('能力', 1112), ('关注', 1110), ('报道', 1108), ('学生', 1103), ('去年', 1101), ('合作', 1100), ('国内', 1089), ('世界', 1079), ('万元', 1062), ('看到', 1051), ('游戏', 1045), ('投资者', 1042), ('网络', 1037), ('考生', 1034), ('最大', 1025), ('金融', 1022), ('亿美元', 1020), ('交易', 1018), ('上涨', 1018), ('娱乐', 1011), ('应该', 994), ('视频', 994), ('媒体', 991), ('政府', 990), ('比较', 988), ('增加', 987), ('上市', 985), ('得到', 982), ('上海', 981), ('研究', 976), ('分钟', 974), ('系统', 968), ('持续', 965), ('约', 960), ('教育', 957)]\n",
      ">>> sampled_test_corpus\n",
      "[('公司', 6159), ('中国', 4944), ('市场', 4717), ('企业', 2867), ('时间', 2557), ('发展', 2479), ('美国', 2392), ('比赛', 2357), ('投资', 2221), ('亿元', 2178), ('经济', 2112), ('基金', 2057), ('情况', 2018), ('产品', 2009), ('出现', 1945), ('工作', 1897), ('增长', 1842), ('手机', 1815), ('技术', 1814), ('用户', 1801), ('行业', 1763), ('数据', 1718), ('影响', 1689), ('相关', 1588), ('球员', 1551), ('提供', 1539), ('银行', 1530), ('北京', 1528), ('业务', 1525), ('未来', 1512), ('信息', 1508), ('服务', 1484), ('国家', 1482), ('希望', 1470), ('网络', 1466), ('价格', 1441), ('学生', 1410), ('平台', 1408), ('科技', 1399), ('计划', 1385), ('表现', 1370), ('国际', 1370), ('股', 1348), ('选择', 1326), ('使用', 1319), ('资金', 1316), ('超过', 1299), ('球队', 1292), ('只', 1282), ('合作', 1273), ('进入', 1252), ('全球', 1239), ('发现', 1235), ('政策', 1227), ('达到', 1225), ('重要', 1218), ('娱乐', 1206), ('支持', 1201), ('孩子', 1199), ('方式', 1192), ('国内', 1191), ('能力', 1190), ('发布', 1181), ('实现', 1166), ('关注', 1166), ('机构', 1159), ('项目', 1153), ('考生', 1146), ('一定', 1139), ('去年', 1132), ('岁', 1130), ('互联网', 1129), ('报道', 1123), ('集团', 1113), ('管理', 1112), ('学校', 1081), ('看到', 1076), ('世界', 1072), ('机会', 1072), ('媒体', 1070), ('电影', 1064), ('投资者', 1058), ('接受', 1050), ('比较', 1049), ('完成', 1048), ('了解', 1042), ('万元', 1035), ('指数', 1035), ('部分', 1033), ('微博', 1031), ('约', 1021), ('之前', 1020), ('交易', 1016), ('最大', 1015), ('风险', 1012), ('调整', 1011), ('应该', 1008), ('预计', 1006), ('教育', 1000), ('存在', 996)]\n"
     ]
    }
   ],
   "source": [
    "print(\">>> sampled_train_corpus\")\n",
    "corpus_count(sampled_train_corpus)\n",
    "print(\">>> sampled_test_corpus\")\n",
    "corpus_count(sampled_test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer & transformer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "# train_X & test_X\n",
    "train_X = tfidf_vectorizer.fit_transform(sampled_train_corpus)\n",
    "test_X = tfidf_vectorizer.transform(sampled_test_corpus)\n",
    "# train_y & test_y\n",
    "train_y = generate_y(pd.read_csv(\"news-sample-train.csv\"))\n",
    "test_y = generate_y(pd.read_csv(\"news-sample-test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (25000, 5000)\n",
      "test_X shape: (25000, 5000)\n",
      "train_y shape: (25000,)\n",
      "test_y shape: (25000,)\n",
      "[ 9. 11.  1. ...  9.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_X shape: {train_X.shape}\")\n",
    "print(f\"test_X shape: {test_X.shape}\")\n",
    "print(f\"train_y shape: {train_y.shape}\")\n",
    "print(f\"test_y shape: {test_y.shape}\")\n",
    "\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=500, silent=True, objective='multi:softmax')\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm\n",
    "lgb_train = lgb.Dataset(test_X, train_y)\n",
    "lgb_test = lgb.Dataset(test_X, test_y, reference=lgb_train)\n",
    "params = {'max_depth': 5, 'min_data_in_leaf': 20, 'num_leaves': 35, \n",
    "          'learning_rate': 0.1, 'lambda_l1': 0.1, 'lambda_l2': 0.2,\n",
    "          'objective': 'multiclass', 'num_class': 12, 'verbose': -1}\n",
    "num_boost_round = 1000\n",
    "\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round, verbose_eval=100, valid_sets=lgb_test)\n",
    "pred_y_possbabilty = gbm.predict(train_X, num_iteration=gbm.best_iteration)\n",
    "pred_y = np.argmax(pred_y_possbabilty, axis=1)\n",
    "\n",
    "print(pred_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.90104\n",
      "precision_score: 0.9011257557233033\n",
      "recall_score: 0.90104\n",
      "f1_score: 0.8999520112952446\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy_score: {accuracy_score(test_y, pred_y)}\")\n",
    "print(f\"precision_score: {precision_score(test_y, pred_y, average='weighted')}\")\n",
    "print(f\"recall_score: {recall_score(test_y, pred_y, average='weighted')}\")\n",
    "print(f\"f1_score: {f1_score(test_y, pred_y, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
